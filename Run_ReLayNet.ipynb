{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Train ReLayNet\n",
    "RunFile of OCT segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from relaynet_pytorch.relay_net import ReLayNet\n",
    "from relaynet_pytorch.data_utils import get_imdb_data\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7\n",
      "Test size: 4\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_imdb_data()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Test size: %i\" % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN.\n",
      "net.forward input.shape: torch.Size([4, 1, 456, 1000])\n",
      "-----------------------------------\n",
      "e1: torch.Size([4, 64, 228, 500]), out1: torch.Size([4, 64, 456, 1000]), ind1: torch.Size([4, 64, 228, 500])\n",
      "e2: torch.Size([4, 64, 114, 250]), out2: torch.Size([4, 64, 228, 500]), ind2: torch.Size([4, 64, 114, 250])\n",
      "e3: torch.Size([4, 64, 57, 125]), out3: torch.Size([4, 64, 114, 250]), ind3: torch.Size([4, 64, 57, 125])\n",
      "-----------------------------------\n",
      "bn: torch.Size([4, 64, 57, 125])\n",
      "-----------------------------------\n",
      "d3: torch.Size([4, 64, 114, 250])\n",
      "d2: torch.Size([4, 64, 228, 500])\n",
      "d1: torch.Size([4, 64, 456, 1000])\n",
      "-----------------------------------\n",
      " * CombinedLoss forward: target unique values: tensor([ nan,  nan,  nan,  ..., 154., 155., 156.])\n",
      "target shape: torch.Size([4, 456, 1000])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m relaynet_model \u001B[38;5;241m=\u001B[39m ReLayNet(param)\n\u001B[0;32m     22\u001B[0m solver \u001B[38;5;241m=\u001B[39m Solver(optim_args\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1e-2\u001B[39m})\n\u001B[1;32m---> 23\u001B[0m \u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrelaynet_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_nth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexp_dir_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp_dir_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\relaynet_pytorch\\relaynet_pytorch\\solver.py:99\u001B[0m, in \u001B[0;36mSolver.train\u001B[1;34m(self, model, train_loader, val_loader, num_epochs, log_nth, exp_dir_name)\u001B[0m\n\u001B[0;32m     97\u001B[0m optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     98\u001B[0m output \u001B[38;5;241m=\u001B[39m model(X)\n\u001B[1;32m---> 99\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m    101\u001B[0m optim\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\relaynet_pytorch\\relaynet_pytorch\\net_api\\losses.py:120\u001B[0m, in \u001B[0;36mCombinedLoss.forward\u001B[1;34m(self, input, target, weight)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# TODO: why?\u001B[39;00m\n\u001B[1;32m--> 120\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLongTensor\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m input_soft \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(\u001B[38;5;28minput\u001B[39m,dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)       \n\u001B[0;32m    123\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_soft shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_soft\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, target shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    286\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    287\u001B[0m     )\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    291\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    292\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    293\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from relaynet_pytorch.relay_net import ReLayNet\n",
    "from relaynet_pytorch.solver import Solver\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "param ={\n",
    "        'num_channels':1,\n",
    "        'num_filters':64,\n",
    "        'kernel_h':3,\n",
    "        'kernel_w':7,\n",
    "        'kernel_c': 1,\n",
    "        'stride_conv':1,\n",
    "        'pool':2,\n",
    "        'stride_pool':2,\n",
    "        'num_class':9\n",
    "    }\n",
    "\n",
    "exp_dir_name = 'Exp01'\n",
    "\n",
    "relaynet_model = ReLayNet(param)\n",
    "solver = Solver(optim_args={\"lr\": 1e-2})\n",
    "solver.train(relaynet_model, train_loader, val_loader, log_nth=1, num_epochs=20, exp_dir_name=exp_dir_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaynet_model.save(\"models/relaynet_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "    {\"id\": 0, \"name\": \"Region above the retina (RaR)\", \"rgb_values\": [128, 0, 0]},\n",
    "    {\"id\": 1, \"name\": \"ILM: Inner limiting membrane\", \"rgb_values\": [0, 128, 0]},\n",
    "    {\"id\": 2, \"name\": \"NFL-IPL: Nerve fiber ending to Inner plexiform layer\", \"rgb_values\": [128, 128, 0]},\n",
    "    {\"id\": 3, \"name\": \"INL: Inner Nuclear layer\", \"rgb_values\": [0, 0, 128]},\n",
    "    {\"id\": 4, \"name\": \"OPL: Outer plexiform layer\", \"rgb_values\": [128, 0, 128]},\n",
    "    {\"id\": 5, \"name\": \"ONL-ISM: Outer Nuclear layer to Inner segment myeloid\", \"rgb_values\": [0, 128, 128]},\n",
    "    {\"id\": 6, \"name\": \"ISE: Inner segment ellipsoid\", \"rgb_values\": [128, 128, 128]},\n",
    "    {\"id\": 7, \"name\": \"OS-RPE: Outer segment to Retinal pigment epithelium\", \"rgb_values\": [64, 0, 0]},\n",
    "    {\"id\": 8, \"name\": \"Region below RPE (RbR)\", \"rgb_values\": [192, 0, 0]}];\n",
    "    #{\"id\": 9, \"name\": \"Fluid region\", \"rgb_values\": [64, 128, 0]}];\n",
    "    \n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networks'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m relaynet_model \u001B[38;5;241m=\u001B[39m  \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodels/Exp01/relaynet_epoch20.model\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m out \u001B[38;5;241m=\u001B[39m relaynet_model(Variable(torch\u001B[38;5;241m.\u001B[39mTensor(test_data\u001B[38;5;241m.\u001B[39mX[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39mcuda(),volatile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m      6\u001B[0m out \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(out,dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1028\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1026\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1027\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1028\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_legacy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1256\u001B[0m, in \u001B[0;36m_legacy_load\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1254\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1255\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1256\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1258\u001B[0m deserialized_storage_keys \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mload(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1260\u001B[0m offset \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;28;01mif\u001B[39;00m f_should_read_directly \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1061\u001B[0m, in \u001B[0;36m_legacy_load.<locals>.UnpicklerWrapper.find_class\u001B[1;34m(self, mod_name, name)\u001B[0m\n\u001B[0;32m   1059\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m   1060\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m-> 1061\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'networks'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "relaynet_model =  torch.load('models/Exp01/relaynet_epoch20.model')\n",
    "out = relaynet_model(Variable(torch.Tensor(test_data.X[0:1]).cuda(),volatile=True))\n",
    "out = F.softmax(out,dim=1)\n",
    "max_val, idx = torch.max(out,1)\n",
    "idx = idx.data.cpu().numpy()\n",
    "idx = label_img_to_rgb(idx)\n",
    "plt.imshow(idx)\n",
    "plt.show()\n",
    "\n",
    "img_test = test_data.X[0:1]\n",
    "img_test = np.squeeze(img_test)\n",
    "plt.imshow(img_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
