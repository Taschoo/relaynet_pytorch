{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ReLayNet\n",
    "RunFile of OCT segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "PyTorch version: 2.3.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from relaynet_pytorch.relay_net import ReLayNet\n",
    "from relaynet_pytorch.data_utils import get_imdb_data\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 7\n",
      "Test size: 4\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_imdb_data()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Test size: %i\" % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN.\n",
      "net.forward input.shape: torch.Size([4, 1, 456, 1000])\n",
      "-----------------------------------\n",
      "e1: torch.Size([4, 64, 228, 500]), out1: torch.Size([4, 64, 456, 1000]), ind1: torch.Size([4, 64, 228, 500])\n",
      "e2: torch.Size([4, 64, 114, 250]), out2: torch.Size([4, 64, 228, 500]), ind2: torch.Size([4, 64, 114, 250])\n",
      "e3: torch.Size([4, 64, 57, 125]), out3: torch.Size([4, 64, 114, 250]), ind3: torch.Size([4, 64, 57, 125])\n",
      "-----------------------------------\n",
      "bn: torch.Size([4, 64, 57, 125])\n",
      "-----------------------------------\n",
      "d3: torch.Size([4, 64, 114, 250])\n",
      "d2: torch.Size([4, 64, 228, 500])\n",
      "d1: torch.Size([4, 64, 456, 1000])\n",
      "-----------------------------------\n",
      " * CombinedLoss forward: target unique values: tensor([ nan,  nan,  nan,  ..., 154., 155., 156.], device='cuda:0')\n",
      "target shape: torch.Size([4, 456, 1000])\n",
      "input_soft shape: torch.Size([4, 9, 456, 1000]), target shape: torch.Size([4, 456, 1000])\n",
      "--> DiceLoss: output.shape torch.Size([4, 9, 456, 1000])  target.shape torch.Size([4, 456, 1000])\n",
      "--> DiceLoss: target unique values: tensor([-9223372036854775808,                    0,                   99,\n",
      "                         100,                  101,                  102,\n",
      "                         103,                  104,                  105,\n",
      "                         106,                  107,                  108,\n",
      "                         109,                  110,                  111,\n",
      "                         112,                  113,                  114,\n",
      "                         115,                  116,                  117,\n",
      "                         118,                  119,                  120,\n",
      "                         121,                  122,                  123,\n",
      "                         124,                  125,                  126,\n",
      "                         127,                  128,                  129,\n",
      "                         130,                  131,                  132,\n",
      "                         133,                  134,                  135,\n",
      "                         136,                  137,                  138,\n",
      "                         139,                  140,                  141,\n",
      "                         142,                  143,                  144,\n",
      "                         145,                  146,                  147,\n",
      "                         148,                  149,                  150,\n",
      "                         151,                  152,                  153,\n",
      "                         154,                  155,                  156],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m relaynet_model \u001b[38;5;241m=\u001b[39m ReLayNet(param)\n\u001b[0;32m     22\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(optim_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-2\u001b[39m})\n\u001b[1;32m---> 23\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelaynet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_nth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_dir_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_dir_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nwolf\\Documents\\GitHub\\relaynet_pytorch\\relaynet_pytorch\\solver.py:99\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self, model, train_loader, val_loader, num_epochs, log_nth, exp_dir_name)\u001b[0m\n\u001b[0;32m     97\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     98\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m---> 99\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    101\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nwolf\\Documents\\GitHub\\relaynet_pytorch\\relaynet_pytorch\\net_api\\losses.py:125\u001b[0m, in \u001b[0;36mCombinedLoss.forward\u001b[1;34m(self, input, target, weight)\u001b[0m\n\u001b[0;32m    121\u001b[0m input_soft \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28minput\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)       \n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_soft shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_soft\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, target shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m y2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdice_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_soft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    126\u001b[0m y1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_entropy_loss\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m, target), weight))\n\u001b[0;32m    127\u001b[0m y \u001b[38;5;241m=\u001b[39m y1 \u001b[38;5;241m+\u001b[39m y2\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nwolf\\Documents\\GitHub\\relaynet_pytorch\\relaynet_pytorch\\net_api\\losses.py:69\u001b[0m, in \u001b[0;36mDiceLoss.forward\u001b[1;34m(self, output, target, weights, ignore_index)\u001b[0m\n\u001b[0;32m     67\u001b[0m     encoded_target[mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mencoded_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# !!? Hier Fehler\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m      \n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from relaynet_pytorch.relay_net import ReLayNet\n",
    "from relaynet_pytorch.solver import Solver\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "param ={\n",
    "        'num_channels':1,\n",
    "        'num_filters':64,\n",
    "        'kernel_h':3,\n",
    "        'kernel_w':7,\n",
    "        'kernel_c': 1,\n",
    "        'stride_conv':1,\n",
    "        'pool':2,\n",
    "        'stride_pool':2,\n",
    "        'num_class':9\n",
    "    }\n",
    "\n",
    "exp_dir_name = 'Exp01'\n",
    "\n",
    "relaynet_model = ReLayNet(param)\n",
    "solver = Solver(optim_args={\"lr\": 1e-2})\n",
    "solver.train(relaynet_model, train_loader, val_loader, log_nth=1, num_epochs=20, exp_dir_name=exp_dir_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relaynet_model.save(\"models/relaynet_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "    {\"id\": 0, \"name\": \"Region above the retina (RaR)\", \"rgb_values\": [128, 0, 0]},\n",
    "    {\"id\": 1, \"name\": \"ILM: Inner limiting membrane\", \"rgb_values\": [0, 128, 0]},\n",
    "    {\"id\": 2, \"name\": \"NFL-IPL: Nerve fiber ending to Inner plexiform layer\", \"rgb_values\": [128, 128, 0]},\n",
    "    {\"id\": 3, \"name\": \"INL: Inner Nuclear layer\", \"rgb_values\": [0, 0, 128]},\n",
    "    {\"id\": 4, \"name\": \"OPL: Outer plexiform layer\", \"rgb_values\": [128, 0, 128]},\n",
    "    {\"id\": 5, \"name\": \"ONL-ISM: Outer Nuclear layer to Inner segment myeloid\", \"rgb_values\": [0, 128, 128]},\n",
    "    {\"id\": 6, \"name\": \"ISE: Inner segment ellipsoid\", \"rgb_values\": [128, 128, 128]},\n",
    "    {\"id\": 7, \"name\": \"OS-RPE: Outer segment to Retinal pigment epithelium\", \"rgb_values\": [64, 0, 0]},\n",
    "    {\"id\": 8, \"name\": \"Region below RPE (RbR)\", \"rgb_values\": [192, 0, 0]}];\n",
    "    #{\"id\": 9, \"name\": \"Fluid region\", \"rgb_values\": [64, 128, 0]}];\n",
    "    \n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "relaynet_model =  torch.load('models/Exp01/relaynet_epoch20.model')\n",
    "out = relaynet_model(Variable(torch.Tensor(test_data.X[0:1]).cuda(),volatile=True))\n",
    "out = F.softmax(out,dim=1)\n",
    "max_val, idx = torch.max(out,1)\n",
    "idx = idx.data.cpu().numpy()\n",
    "idx = label_img_to_rgb(idx)\n",
    "plt.imshow(idx)\n",
    "plt.show()\n",
    "\n",
    "img_test = test_data.X[0:1]\n",
    "img_test = np.squeeze(img_test)\n",
    "plt.imshow(img_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
